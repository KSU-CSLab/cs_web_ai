{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# 샘플 데이터 (더 확장 가능)\n",
    "pairs = [\n",
    "    [\"hello\", \"hi\"],\n",
    "    [\"how are you\", \"i am fine\"],\n",
    "    [\"what is your name\", \"i am chatbot\"],\n",
    "    [\"bye\", \"see you\"]\n",
    "]\n",
    "\n",
    "\n",
    "# 간단한 토큰 사전 생성\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n",
    "        self.idx2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.word_count = 3\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            if word not in self.word2idx:\n",
    "                self.word2idx[word] = self.word_count\n",
    "                self.idx2word[self.word_count] = word\n",
    "                self.word_count += 1\n",
    "\n",
    "    def sentence_to_ids(self, sentence):\n",
    "        return [self.word2idx[word] for word in sentence.split()] + [2]  # EOS\n",
    "\n",
    "    def ids_to_sentence(self, ids):\n",
    "        return ' '.join([self.idx2word[i] for i in ids if i not in [0, 1, 2]])\n",
    "\n",
    "\n",
    "vocab = Vocab()\n",
    "for q, a in pairs:\n",
    "    vocab.add_sentence(q)\n",
    "    vocab.add_sentence(a)\n",
    "\n",
    "# 파라미터\n",
    "VOCAB_SIZE = vocab.word_count\n",
    "EMBED_SIZE = 16\n",
    "HIDDEN_SIZE = 32\n",
    "\n",
    "\n",
    "# 인코더\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_SIZE)\n",
    "        self.gru = nn.GRU(EMBED_SIZE, HIDDEN_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "# 디코더\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_SIZE)\n",
    "        self.gru = nn.GRU(EMBED_SIZE, HIDDEN_SIZE)\n",
    "        self.out = nn.Linear(HIDDEN_SIZE, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x).unsqueeze(0)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out(output.squeeze(0))\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "enc_optimizer = torch.optim.Adam(encoder.parameters())\n",
    "dec_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "\n",
    "# 훈련 루프\n",
    "for epoch in range(1000):\n",
    "    idx = random.randint(0, len(pairs) - 1)\n",
    "    input_seq = torch.tensor(vocab.sentence_to_ids(pairs[idx][0]), dtype=torch.long).unsqueeze(1)\n",
    "    target_seq = torch.tensor(vocab.sentence_to_ids(pairs[idx][1]), dtype=torch.long)\n",
    "\n",
    "    enc_hidden = encoder(input_seq)[-1].unsqueeze(0)\n",
    "\n",
    "    loss = 0\n",
    "    dec_input = torch.tensor([1])  # SOS\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    for t in range(len(target_seq)):\n",
    "        output, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "        loss += criterion(output, target_seq[t].unsqueeze(0))\n",
    "        dec_input = target_seq[t].unsqueeze(0)\n",
    "\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    enc_optimizer.step()\n",
    "    dec_optimizer.step()\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# 추론 함수\n",
    "def respond(sentence):\n",
    "    with torch.no_grad():\n",
    "        input_seq = torch.tensor(vocab.sentence_to_ids(sentence), dtype=torch.long).unsqueeze(1)\n",
    "        enc_hidden = encoder(input_seq)\n",
    "\n",
    "        dec_input = torch.tensor([1])  # SOS\n",
    "        dec_hidden = enc_hidden\n",
    "        result = []\n",
    "\n",
    "        for _ in range(10):\n",
    "            output, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            next_word = topi.item()\n",
    "            if next_word == 2:  # EOS\n",
    "                break\n",
    "            result.append(next_word)\n",
    "            dec_input = topi.detach()\n",
    "\n",
    "        return vocab.ids_to_sentence(result)\n",
    "\n",
    "\n",
    "# 예시\n",
    "print(respond(\"hello\"))\n",
    "print(respond(\"what is your name\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
